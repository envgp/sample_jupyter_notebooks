{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Day 2\n",
    "----\n",
    "____\n",
    "____\n",
    "**Goals for Today**\n",
    "* Learn basic data manipulation\n",
    "    * adding/deleting data elements\n",
    "    * array slicing\n",
    "    * relevant data processing libraries/tools\n",
    "    \n",
    "* Learn the basics of matplotlib\n",
    "    * 1D plots\n",
    "    * creating axes labels and titles\n",
    "    * plot symbology (color, size, etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Import\n",
    "----\n",
    "____\n",
    "Go ahead and import the following packages:\n",
    "* numpy (as np)\n",
    "* matplotlib (as plt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Import\n",
    "----\n",
    "____\n",
    "\n",
    "On day one, we gave you a pretty complicated .txt file to manipulate and optimize file input/output. This information will continue to be very useful throughout this course (and your career), however for this section, we are going to dial input/output formatting back and focus on manipulation of the actual data. Go ahead and load in `PRK_test1.txt` and `PRK_test2.txt` as numpy array and save each .txt file as float variable, `test1` and `test2` respectively. \n",
    "\n",
    "Once you have loaded in the file, explore the datasets. You can use `np.shape()` to determine the size and dimensions of the array. You can also print the first few lines of each array using a simple for loop. This may look like the following: \n",
    "```\n",
    "print(\"dataset #1\")\n",
    "for i in range(0,5):\n",
    "    print(test1[i])\n",
    "print(\"dataset #2\")\n",
    "for i in range(0,5):\n",
    "    print(test2[i])\n",
    "\n",
    "```\n",
    "This tells the computer to print the first five rows of each dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial interpretation of Data\n",
    "----\n",
    "___\n",
    "From these basic commands, we've learned the following about our data:\n",
    "* each dataset is a one dimensional array with 1440 entries\n",
    "*  the values of test 1 are almost double those of test two\n",
    "\n",
    "This information is interesting, but we still don't know what the datasets represent, or anything about the data points past the first five entries. To learn more, lets make some very basic plots using `matplotlib`, Python's plotting library. We've already imported `matplotlib` as `.plt`. Similar to using `.np`, to access any of the commands in the `matplotlib` library, we will use the following structure: `plt.desiredCommand()`.  \n",
    "\n",
    "To plot the first dataset, try the following:\n",
    "```\n",
    "plt.plot(test1)\n",
    "plt.title(\"Test one Results\")\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developing Plots\n",
    "----\n",
    "___\n",
    "Now that we know what test one looks like, lets try to compare it to test two. There are two ways to do this--plotting the datasets side by side, and plotting them on top of eachother. For fun, lets try both. \n",
    "\n",
    "To plot the data sets next to eachother, we'll used the `plt.subplot()` module. For our purposes, this will look like this:\n",
    "```\n",
    "plt.subplot(211)\n",
    "plt.plot(test1)\n",
    "plt.title(\"Test one Results\")\n",
    "plt.subplot(212)\n",
    "plt.plot(test2)\n",
    "plt.title(\"Test two Results\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n",
    "within the `plt.subplot()` argument, you'll notice three numbers. The first number tells the function how many rows you'd like to have plots on, the second number tells the function how many columns you'd like to have plots on, and the third number indexes the subplot, meaning it gives the function an order to place the plot. `plt.tight_layout()` simply puts some extra space between the plots so they don't look crowded. \n",
    "\n",
    "\n",
    "\n",
    "To plot the datasets on top of eachother, we don't need to use the subplot module. Instead, we'll do the following:\n",
    "```\n",
    "plt.plot(test1,label=\"test one\")\n",
    "plt.plot(test2,label=\"test two\")\n",
    "plt.title(\"Test one and Test Two Results\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "Since we are plotting two things in the same plot, it is very important to create a legend. The `label` arguement in `plt.plot()` titles each plot so it can be properly shown when the command `plt.legend()` is used. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## insert your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving our interpretation\n",
    "----\n",
    "___\n",
    "Now that we have some plots of our data, we know a lot more about it. Both datasets appear to have two major events, one around x=1000, and one around x=2500. \n",
    "\n",
    "After the second event, the data begins to taper, and looks to be irrelevant. Before the first event, the data looks totally flat--there is no signal up until the first event begins. Lets try getting rid of all datapoints after before x=1000 and after x=5000 so we can get a better look at the events. \n",
    "\n",
    "In certain programming languages, to remove values, you'd have to implement a for-loop. In Python, however, we can use a very powerful trick--array slicing. To remove all of the data points before x=1000 and after x=5000 using array slicing, use the following command:\n",
    "```\n",
    "test1=np.asarray(test1[1000:5000],dtype=float)\n",
    "test2=np.asarray(test2[1000:5000],dtype=float)\n",
    "```\n",
    "The first number means to start at that element in the array, the colon indicates that we want to slice the array, and the last number means to end slicing at that place in the array. We also wrap our arguement in `np.asarray(,dtype=float)` to ensure that during the slicing process the data type doesn't accidentally become a string. \n",
    "\n",
    "Lets splice our arrays, then create a new set of plots. This time, lets try three subplots: a plot of the sliced first test, a plot of the spliced second test, and a plot of the two sliced datasets overlain on eachother. \n",
    "\n",
    "learn more about array slicing [here](https://docs.scipy.org/doc/numpy/reference/arrays.indexing.html) and [here](https://machinelearningmastery.com/index-slice-reshape-numpy-arrays-machine-learning-python/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improving our plots\n",
    "----\n",
    "___\n",
    "\n",
    "Wow! These plots are great, and we are begining to see some cool things in our data--well sort of. As you probably noticed, these plots are tiny. To improve this, we will make use of the `plt.figure()` function. For fun, let's also make our font sizes bigger. Lets try:\n",
    "\n",
    "```\n",
    "plt.figure(figsize=(20,10))\n",
    "\n",
    "plt.subplot(311)\n",
    "plt.plot(test1)\n",
    "plt.title(\"Test one Results\", fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "plt.subplot(312)\n",
    "plt.plot(test2)\n",
    "plt.title(\"Test two Results\", fontsize=20)\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "plt.subplot(313)\n",
    "plt.plot(test1,label=\"test one\")\n",
    "plt.plot(test2,label=\"test two\")\n",
    "plt.title(\"Test one and Test Two Results\", fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel(\"Number of Points\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.tick_params(labelsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So what the heck am I looking at?\n",
    "----\n",
    "___\n",
    "Now that your plots look great, its time to determine what exactly you're looking at. As mentioned earlier, both datasets appear to have two major events. They also have a lose wave-like structure, with an amplitude that changes in response to each event. \n",
    "\n",
    "Any ideas what this could be? \n",
    "\n",
    "If you guessed a seismogram--a recording of a seismic event--you are correct! Both datasets are actually seismic responses to North Korean nuclear tests. Specifically, they are ground motion signals arriving at the MDJ seismic station located in Mudanjiang, Heilongjiang Province, China. The first dataset was collected on 09/03/2017 and the second dataset was collected a year earlier, on 09/09/2016. \n",
    "\n",
    "There are three features that we can easily identify in these datasets: \n",
    "* the P-wave arrival: occurs around x=100\n",
    "* the S-wave arrival: occurs around x=300\n",
    "* the surface waves: become prominent around x=1500\n",
    "\n",
    "If you aren't familar with these wave types, check out [this website](http://www.geo.mtu.edu/UPSeis/waves.html) for an easy to read resource. It will be very useful to know what the data means as you manipulate it! Additionally, [this website](http://www.geo.mtu.edu/UPSeis/reading.html) and [this one (pages 1 and 2)](http://www.iris.edu/hq/files/programs/education_and_outreach/aotm/17/SeismicSignatures_SeismogramMSH%20addition.pdf) give some good information on reading seismograms. Lastly, [this](http://seismo.berkeley.edu/blog/2009/05/25/of-nuclear-bombs-and-earthquakes.html) is a great blog post that explains specifically how to interpret seismograms that are sourced from nuclear explosions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Math with NumPy Arrays\n",
    "----\n",
    "___\n",
    "As we've mentioned in class, NumPy makes it very easy to add, subtract, divide, and multiply arrays. To test this, let's try the following with our dataset:\n",
    "* find the percent difference in P-wave and S-wave arrival waves in the test one dataset\n",
    "* determine how much larger the 2017 event's magnitude is compared to that of the 2016 event\n",
    "\n",
    "### comparing S waves and P waves\n",
    "As you gathered from the first website cited in the cell above, P-waves and S-waves are both considered types of body waves. P-waves are compression waves, meaning that they apply a force in the direction of propegation. The earth's interior is almost totally incompressible, so P-waves transmit their energy easily, thus traveling quickly through the earth, leaving a seismic signature relatively small in magnitude. S-waves on the other hand are shear waves, and move perpendicular to the to the earth's interior. Energy is not as efficiently transmitted this way, so S-waves move more slowly through the earth, leaving a larger seismic signature. On average, P-waves move 60% faster than S waves! \n",
    "\n",
    "I am interested in seeing how big the magnitude difference between the arrival of each wave is. To do this, the first thing I need to do is find where exactly each arrival wave is. Since we know that the P-wave arrives somewhere around x=100 and the P-wave arrives somewhere around x=300, using array slicing, we can create an array that allows us to look specifically during this time period. Let's create this array for the first test via the following code:\n",
    "```\n",
    "rangeS=test1[0:300]\n",
    "```\n",
    "We also know that during ``PSrange``, the P-wave arrival will have the largest spike, and the S-wave arrival will have the second largest spike. using np.amax() and np.where() we can find where each arrival is. \n",
    "First let's find the S-wave using the following code snippet:\n",
    "\n",
    "```\n",
    "yS=np.amax(rangeS)\n",
    "xS=np.where(rangeS==yS)\n",
    "print(\"The x location of the S-wave arrival is: %f \\n The Y location of the S-wave arrival is %s\" % (xS[0],yS))\n",
    "```\n",
    "You should get (xS,yS)=(289, 2472638) for the S-wave arrival coordinate. \n",
    "\n",
    "To find the P-wave, we can repeat the same process, but with a smaller array slice. Try:\n",
    "```\n",
    "rangeP=test1[0:110]\n",
    "yP=np.amax(rangeP)\n",
    "xP=np.where(rangeP==yP)\n",
    "print(\"The x location of the P-wave arrival is: %f \\n The Y location of the S-wave arrival is %s\" % (xP[0],yP))\n",
    "\n",
    "```\n",
    "Note: to avoid indexing errors, it is typically easier to slice an array starting 0. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing P and S waves (continued)\n",
    "\n",
    "using `yS` and `yP`, lets figure out how much bigger the S-wave arrival is than the P-wave arrival. To do this, we will used the normalized percent increase equation:\n",
    "$$\n",
    "\\% increase=\\frac{y_s-y_p}{y_S}*100\n",
    "$$\n",
    "\n",
    "Coding up this equation using NumPy arrays is very simple. Try:\n",
    "```\n",
    "percentIncrease=(yS-yP)/(yS)*100\n",
    "```\n",
    "or alternatively:\n",
    "```\n",
    "percentIncrease=np.multiply(np.divide(np.subtract(yS,yP),yS),100)\n",
    "```\n",
    "On your own, try getting the output to say something like \"The S-wave arrival is `percentIncrease` percent bigger than the P-wave arrival. Be sure to use the actual variable, `percentIncrease` in your output! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing test one to test two\n",
    "So we now know how to compare one specific point in a dataset to another, but how can we compare two complete datasets to eachother? First, lets take the exact same approach that we took to find the percent increase between the P and S-wave arrivals. \n",
    "\n",
    "Try: \n",
    "```\n",
    "percentIncrease1=(np.abs(test1)-np.abs(test2))/(test1)*100\n",
    "```\n",
    "Note: We use `np.abs()` because these datasets have positive and negative values, and ultimately, we only care about the magnitude of difference and want to avoid sign errors. \n",
    "\n",
    "\n",
    "This method will result in an array, where each point in test one has been subtracted and divided by each point in test two. Go ahead and make a simple plot of the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing test one to test two (continued)\n",
    "This plot looks super wonky--there are a few 'txtbf{huge} outlying points, but everything else looks like there's almost no difference. If you zoom in on the plot by including `plt.ylim(-1000,1000)` in your figure commands, things look even weirder. This is because though the events of the datasets basically line up, each point in test one is off by just a little bit from its counterpart in test two. Thus, the method of comparing each point to its counterpart doesn't really work. See what I mean by plotting:\n",
    "```\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(test1)\n",
    "plt.plot(test2)\n",
    "plt.xlabel(\"Number of Points\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.xlim(100,300)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing test one to test two (continued)\n",
    "As the plot shows, the wave peaks are off just a little bit. This is because `test2` is so much smaller than `test1` that it is propegating through the earth more slowly, creating longer periods. \n",
    "Because we are just looking for a total percent difference anyway, we don't have to do any hardcore signal manipulation to our data to make the peaks match up (save this for seismic data processors!). Instead, we will take the absolute mean of each dataset, then calculate percent difference from out average values.\n",
    "\n",
    "Try:\n",
    "```\n",
    "test1Mean=np.mean(np.abs(test1))\n",
    "test2Mean=np.mean(np.abs(test2))\n",
    "percentIncreaseTot=(test1Mean-test2Mean)/(test1Mean)*100\n",
    "print(\"test one is %f percent bigger than test two\" %percentIncreaseTot)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holy Guacamole, what a difference a year can make! \n",
    "<img src=\"https://media2.giphy.com/media/wUTUBrRYwxMVW/giphy.gif\" \\>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting nuclear test strength over the next 10 years\n",
    "----\n",
    "___\n",
    "Now that we know the percent growth from one year to the next, we can use a fitting model to determine how much stronger the DPRK's nuclear weaponry will be 10 years from now. There are an infinite number of models we can use, but for simplicity, we are going to try two simpler ones: a linear fit and an exponential fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting percent increase in strength using a linear fit:\n",
    "Right now, we have two sets of coordinates: $(x_{test1},y_{test1}), (x_{test2},y_{test2})$ where\n",
    "* $x_{test1}$=2017\n",
    "* $y_{test1}$=`test1Mean`\n",
    "* $x_{test2}$=2016\n",
    "* $y_{test2}$=`test2Mean`. \n",
    "\n",
    "Using these points and some basic algebra, we can find the slope of the line between our data, $m$. Recall:\n",
    "$$\n",
    "m=\\frac{y_2-y_1}{x_2-x_1}\n",
    "$$\n",
    "applied to our coordinates: \n",
    "$$\n",
    "m=\\frac{y_{test1}-y_{test2}}{x_{test1}-x_{test2}}\n",
    "$$\n",
    "\n",
    "Up until now, time has been relative, so we have been working with 1D arrays. This equation is relatively simple to code up, but to do it, we need to actually introduce a time variable, in this case the year. We know that `test1` was recorded in 2017, and `test2` was recorded in 2016, so we can do the following:\n",
    "```\n",
    "tests=[test2Mean,test1Mean]\n",
    "year=[2016,2017]\n",
    "```\n",
    "This creates two seperate 1D arrays, one for time, and one for the mean test values. We could have also done something like: \n",
    "```\n",
    "test1=[2017,test1Mean]\n",
    "test2=[2016,test2Mean]\n",
    "``` \n",
    "however as we continue on, you will see that it is easier to keep track of your arrays if you seperate them by variable type, and not by coordinates. \n",
    "\n",
    "We know that the 2017 test is `percentIncreaseTot`=89% bigger than the 2016 test. If we follow this same liner trajectory, than the 2018 test will be 89% bigger than 2017, 2019 will be 89% bigger than 2018, and so on. We can use this trajectory to find the correct slope, `m`, for our linear model.  \n",
    "\n",
    "To start, lets initialize our new arrays and plot what we have so far:\n",
    "```\n",
    "tests=[test2Mean,test1Mean]\n",
    "year=[2016,2017]\n",
    "\n",
    "plt.plot(year[0],tests[0],'bo',)\n",
    "plt.plot(year[1],tests[1],'bo')\n",
    "plt.plot(year,tests, 'g')\n",
    "plt.title(\"The Average strength of DPRK Nuclear Tests\")\n",
    "plt.show()\n",
    "```\n",
    "The `'bo'` arguement in the `plt.plot()` function simply makes the point a blue dot, and `g` makes the line green\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting percent increase in strength using a linear fit (continued):\n",
    "To predict the mean test strength 10 years from now (2028), we need to formulate each of the variables for the green line plotted in the equation above. Recall:\n",
    "$$\n",
    "y=mx+b\n",
    "$$\n",
    "$$\n",
    "m=\\frac{y_2-y_1}{x_2-x_1}\n",
    "$$\n",
    "$$\n",
    "b=y_0\n",
    "$$\n",
    "Now, we could go through and solve for each of these variables manually, or by using basic math functions, but NumPy's linear algebra module, `np.linalg()` has a function `np.linalg.lstsq()` that will solve for $m$ and $b$ for us. Lets try it:\n",
    "```\n",
    "A = np.vstack([year, np.ones(len(year))]).T\n",
    "m, b = np.linalg.lstsq(A, tests)[0]\n",
    "```\n",
    "If you haven't taken linear algebra or advanced engineering math, you may not understand the meaning behind the transposed matrix I created, `A.T`. That's totally ok. As you continue on with coursework in the department, you will eventually understand the math behind it, but for now just know that it is an operator that makes it possible for the computer to solve for $m$ and $b$ in a matrix. \n",
    "\n",
    "You can check out the docs for `np.linalg.lstsq()` [here](https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.linalg.lstsq.html)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting percent increase in strength using a linear fit (continued):\n",
    "To generate some x values, we will initialze an array that has years 2016-2028 using `np.arange()`. \n",
    "this will look like:\n",
    "```\n",
    "x=np.arange(2016,2029)\n",
    "```\n",
    "Remember, we want years up to (and including) 2028. Therefore, we need to add one to the index!\n",
    "Now that we have $m,x,b$ we can find variable $y$, the absolute mean strength of the test, for each year using the linear fit equation, $y=mx+b$.\n",
    "\n",
    "Let's make y and modify our initial plot to include it. \n",
    "```\n",
    "y=m*x+b\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.plot(year[0],tests[0],'bo',label=\"recorded values\")\n",
    "plt.plot(year[1],tests[1],'bo')\n",
    "plt.plot(x[12],y[12], 'ro', label=\"2028 prediction\")\n",
    "plt.title(\"The Average strength of DPRK Nuclear Tests\") \n",
    "plt.xlabel(\"year\")\n",
    "plt.ylabel(\"Absolute mean strength\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```\n",
    "Note the usage of `plt.xlabel()` and `plt.ylabel()`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlating our prediction back to our known points\n",
    "The last thing we are going to do is determine just how much larger our 2028 prediction is than the known 2016 test. To do this, use the same percent increase formula that you used to make `percentIncreaseTot`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "##insert your code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
